{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import KFold\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import Zeros, Constant\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# reset project root\n",
    "PROJECT_ROOT = \"/home/zahra/Synthetic_Landscapes/mutation-predictability\"\n",
    "DATA_ROOT =  \"/home/zahra/Synthetic_Landscapes/Data\"\n",
    "\n",
    "from predictability.models import PottsRegressor, PottsModel\n",
    "from predictability.utils import update_environment_variables\n",
    "from predictability.constants import BINARY_RESIDUE_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Francesca\n",
    "\n",
    "- Refer to https://github.com/florisvdf/mutation-predictability for info on downloading Gremlin\n",
    "- Change PROJECT_ROOT and DATA_ROOT\n",
    "- Change folder/file names\n",
    "- if loading new MSA file, rerun fxn to convert a2m (downloaded from EVcoulpings) to a3m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only necessary when jupyter does not read EVs, replace zsh with your shell\n",
    "update_environment_variables(\"zsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/zahra/Synthetic_Landscapes/Potts/results/GB1/\"\n",
    "results_dir = Path(path)\n",
    "results_dir.mkdir(exist_ok=True, parents=True)\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convet a2m to a3m (only need to run once)\n",
    "# def format_a2m(msa_path):\n",
    "#     file_name = Path(msa_path).name\n",
    "#     directory = Path(msa_path).parent\n",
    "#     formatted_msa_path = f\"{directory}/modified_{file_name}\"\n",
    "#     with open(msa_path, \"r\") as rf:\n",
    "#         with open(formatted_msa_path, \"w\") as wf:\n",
    "#             for line in rf:\n",
    "#                 if line.startswith(\">\"):\n",
    "#                     wf.write(line)\n",
    "#                 else:\n",
    "#                     wf.write(line.upper().replace(\".\", \"-\"))\n",
    "#     return formatted_msa_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta(filename, a3m=True):\n",
    "  '''function to parse fasta file'''\n",
    "  \n",
    "  if a3m:\n",
    "    # for a3m files the lowercase letters are removed\n",
    "    # as these do not align to the query sequence\n",
    "    rm_lc = str.maketrans(dict.fromkeys(string.ascii_lowercase))\n",
    "    \n",
    "  header, sequence = [],[]\n",
    "  lines = open(filename, \"r\")\n",
    "  for line in lines:\n",
    "    line = line.rstrip()\n",
    "    if line[0] == \">\":\n",
    "      header.append(line[1:])\n",
    "      sequence.append([])\n",
    "    else:\n",
    "      if a3m: line = line.translate(rm_lc)\n",
    "      else: line = line.upper()\n",
    "      sequence[-1].append(line)\n",
    "  lines.close()\n",
    "  sequence = [''.join(seq) for seq in sequence]\n",
    "  return header, sequence\n",
    "  \n",
    "def mk_msa(seqs):\n",
    "  '''one hot encode msa'''\n",
    "  alphabet = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "  states = len(alphabet)\n",
    "  \n",
    "  alpha = np.array(alphabet, dtype='|S1').view(np.uint8)\n",
    "  msa = np.array([list(s) for s in seqs], dtype='|S1').view(np.uint8)  \n",
    "  for n in range(states):\n",
    "    msa[msa == alpha[n]] = n  \n",
    "  msa[msa > states] = states-1\n",
    "  \n",
    "  return np.eye(states)[msa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GREMLIN_simple(msa, msa_weights=None, lam=0.01, \n",
    "                   opt=None, opt_rate=None,\n",
    "                   opt_batch=None, opt_epochs=100):\n",
    "  '''\n",
    "  ------------------------------------------------------\n",
    "  inputs\n",
    "  ------------------------------------------------------\n",
    "   msa         : msa input       shape=(N,L,A)\n",
    "   msa_weights : weight per seq  shape=(N,)\n",
    "  ------------------------------------------------------\n",
    "  optional inputs\n",
    "  ------------------------------------------------------\n",
    "   lam         : L2 regularization weight\n",
    "   opt         : optimizer\n",
    "   opt_rate    : learning rate\n",
    "   opt_batch   : batch size\n",
    "   opt_epochs  : number of epochs\n",
    "  ------------------------------------------------------\n",
    "  outputs \n",
    "  ------------------------------------------------------\n",
    "   v           : conservation    shape=(L,A)\n",
    "   w           : coevolution     shape=(L,A,L,A)\n",
    "  ------------------------------------------------------\n",
    "  '''\n",
    "  \n",
    "  # [N]umber of sequences, [L]ength, and size of [A]lphabet\n",
    "  N,L,A = msa.shape\n",
    "    \n",
    "  # reset any open sessions/graphs\n",
    "  K.clear_session()\n",
    "  \n",
    "  #############################\n",
    "  # the model\n",
    "  #############################  \n",
    "  \n",
    "  # constraints\n",
    "  def cst_w(x):\n",
    "    '''symmetrize, set diagonal to zero'''\n",
    "    x = (x + K.transpose(x))/2    \n",
    "    zero_mask = K.constant((1-np.eye(L))[:,None,:,None],dtype=tf.float32)\n",
    "    x = K.reshape(x,(L,A,L,A)) * zero_mask\n",
    "    return K.reshape(x,(L*A,L*A))\n",
    "  \n",
    "  # initialiation\n",
    "  if msa_weights is None:\n",
    "    Neff = N\n",
    "    pssm = msa.sum(0)\n",
    "  else:\n",
    "    Neff = msa_weights.sum()\n",
    "    pssm = (msa.T*msa_weights).sum(-1).T\n",
    "  \n",
    "  ini_v = np.log(pssm + lam * np.log(Neff))\n",
    "  ini_v = Constant(ini_v - ini_v.mean(-1,keepdims=True))\n",
    "  ini_w = Zeros\n",
    "  \n",
    "  # regularization\n",
    "  lam_v = l2(lam/N)\n",
    "  lam_w = l2(lam/N * (L-1)*(A-1)/2)\n",
    "  \n",
    "  # model\n",
    "  model = Sequential()\n",
    "  model.add(Flatten(input_shape=(L,A)))\n",
    "  model.add(Dense(units=L*A,\n",
    "                  kernel_initializer=ini_w,\n",
    "                  kernel_regularizer=lam_w,\n",
    "                  kernel_constraint=cst_w,\n",
    "                  bias_initializer=ini_v,\n",
    "                  bias_regularizer=lam_v)) \n",
    "  model.add(Reshape((L,A)))\n",
    "  model.add(Activation(\"softmax\"))\n",
    "  \n",
    "  #############################\n",
    "  # compile model\n",
    "  #############################\n",
    "  # loss function = CCE = -Pseudolikelihood\n",
    "  @tf.function\n",
    "  def CCE(true,pred):\n",
    "    return K.sum(-true * K.log(pred + 1e-8),axis=(1,2))\n",
    "  \n",
    "  # optimizer settings\n",
    "  if opt is None: opt = Adam\n",
    "  if opt_rate is None: opt_rate = 0.1 * np.log(Neff)/L\n",
    "  if opt_batch is None: opt_batch = N\n",
    "\n",
    "  model.compile(opt(opt_rate),CCE)  \n",
    "    \n",
    "  #############################\n",
    "  # fit model\n",
    "  #############################\n",
    "  model.fit(msa, msa, sample_weight=msa_weights,\n",
    "            batch_size=opt_batch, epochs=opt_epochs,\n",
    "            verbose=False)\n",
    "\n",
    "  # report loss\n",
    "  loss = model.evaluate(msa, msa, sample_weight=msa_weights, verbose=False) * N\n",
    "  print(f\"loss: {loss}\")\n",
    "  \n",
    "  #############################\n",
    "  # return weights\n",
    "  #############################\n",
    "  w,v = model.get_weights()\n",
    "  return v.reshape((L,A)), w.reshape((L,A,L,A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 13:50:33.048328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19868 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2023-12-11 13:50:33.049792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22280 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n",
      "2023-12-11 13:50:38.113735: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-11 13:50:46.218321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f43080f44d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-11 13:50:46.218417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-12-11 13:50:46.218435: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-12-11 13:50:46.229344: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-11 13:50:46.622390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-12-11 13:50:46.843886: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 731118.1656723022\n",
      "CPU times: user 49.6 s, sys: 39.1 s, total: 1min 28s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "names, seqs = parse_fasta(str(DATA_ROOT + \"/GB1/GB1_b0.3_b0.5_joined.a3m\"), a3m=True)\n",
    "msa = mk_msa(seqs)\n",
    "\n",
    "#potts_model = PottsRegressor(msa_path=str(DATA_ROOT / \"amylase/msa.a3m\"))\n",
    "V, W = GREMLIN_simple(msa, msa_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zahra/Synthetic_Landscapes/Potts/results/GB1/output.npz\n"
     ]
    }
   ],
   "source": [
    "path = str(results_dir) + '/output.npz'\n",
    "data = np.savez(path, V, W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
